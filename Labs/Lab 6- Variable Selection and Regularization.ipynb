{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: 'Lab 6: Variable Selection and Regularization'\n",
    "author: Oscar Luo\n",
    "format:\n",
    "    html:\n",
    "        toc: true\n",
    "        code-fold: true\n",
    "embed-resources: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import plotnine as p9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>293</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>293</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>446</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>497</td>\n",
       "      <td>127</td>\n",
       "      <td>7</td>\n",
       "      <td>65</td>\n",
       "      <td>48</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>2703</td>\n",
       "      <td>806</td>\n",
       "      <td>32</td>\n",
       "      <td>379</td>\n",
       "      <td>311</td>\n",
       "      <td>138</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>325</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>492</td>\n",
       "      <td>136</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>50</td>\n",
       "      <td>94</td>\n",
       "      <td>12</td>\n",
       "      <td>5511</td>\n",
       "      <td>1511</td>\n",
       "      <td>39</td>\n",
       "      <td>897</td>\n",
       "      <td>451</td>\n",
       "      <td>875</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>313</td>\n",
       "      <td>381</td>\n",
       "      <td>20</td>\n",
       "      <td>875.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>475</td>\n",
       "      <td>126</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>1700</td>\n",
       "      <td>433</td>\n",
       "      <td>7</td>\n",
       "      <td>217</td>\n",
       "      <td>93</td>\n",
       "      <td>146</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "      <td>7</td>\n",
       "      <td>385.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>573</td>\n",
       "      <td>144</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "      <td>60</td>\n",
       "      <td>78</td>\n",
       "      <td>8</td>\n",
       "      <td>3198</td>\n",
       "      <td>857</td>\n",
       "      <td>97</td>\n",
       "      <td>470</td>\n",
       "      <td>420</td>\n",
       "      <td>332</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>1314</td>\n",
       "      <td>131</td>\n",
       "      <td>12</td>\n",
       "      <td>960.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>631</td>\n",
       "      <td>170</td>\n",
       "      <td>9</td>\n",
       "      <td>77</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>4908</td>\n",
       "      <td>1457</td>\n",
       "      <td>30</td>\n",
       "      <td>775</td>\n",
       "      <td>357</td>\n",
       "      <td>249</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>408</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>322 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AtBat  Hits  HmRun  Runs  RBI  ...  PutOuts  Assists  Errors  Salary  NewLeague\n",
       "0      293    66      1    30   29  ...      446       33      20     NaN          A\n",
       "1      315    81      7    24   38  ...      632       43      10   475.0          N\n",
       "2      479   130     18    66   72  ...      880       82      14   480.0          A\n",
       "3      496   141     20    65   78  ...      200       11       3   500.0          N\n",
       "4      321    87     10    39   42  ...      805       40       4    91.5          N\n",
       "..     ...   ...    ...   ...  ...  ...      ...      ...     ...     ...        ...\n",
       "317    497   127      7    65   48  ...      325        9       3   700.0          N\n",
       "318    492   136      5    76   50  ...      313      381      20   875.0          A\n",
       "319    475   126      3    61   43  ...       37      113       7   385.0          A\n",
       "320    573   144      9    85   60  ...     1314      131      12   960.0          A\n",
       "321    631   170      9    77   44  ...      408        4       3  1000.0          A\n",
       "\n",
       "[322 rows x 20 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitters = pd.read_csv('/Users/oscarluo/Downloads/Hitters.csv')\n",
    "hitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtBat         0\n",
       "Hits          0\n",
       "HmRun         0\n",
       "Runs          0\n",
       "RBI           0\n",
       "Walks         0\n",
       "Years         0\n",
       "CAtBat        0\n",
       "CHits         0\n",
       "CHmRun        0\n",
       "CRuns         0\n",
       "CRBI          0\n",
       "CWalks        0\n",
       "League        0\n",
       "Division      0\n",
       "PutOuts       0\n",
       "Assists       0\n",
       "Errors        0\n",
       "Salary       59\n",
       "NewLeague     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at missing data\n",
    "hitters.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-14>:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>293</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>293</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>446</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>535.925882</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.500000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>497</td>\n",
       "      <td>127</td>\n",
       "      <td>7</td>\n",
       "      <td>65</td>\n",
       "      <td>48</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>2703</td>\n",
       "      <td>806</td>\n",
       "      <td>32</td>\n",
       "      <td>379</td>\n",
       "      <td>311</td>\n",
       "      <td>138</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>325</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>492</td>\n",
       "      <td>136</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>50</td>\n",
       "      <td>94</td>\n",
       "      <td>12</td>\n",
       "      <td>5511</td>\n",
       "      <td>1511</td>\n",
       "      <td>39</td>\n",
       "      <td>897</td>\n",
       "      <td>451</td>\n",
       "      <td>875</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>313</td>\n",
       "      <td>381</td>\n",
       "      <td>20</td>\n",
       "      <td>875.000000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>475</td>\n",
       "      <td>126</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>1700</td>\n",
       "      <td>433</td>\n",
       "      <td>7</td>\n",
       "      <td>217</td>\n",
       "      <td>93</td>\n",
       "      <td>146</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "      <td>7</td>\n",
       "      <td>385.000000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>573</td>\n",
       "      <td>144</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "      <td>60</td>\n",
       "      <td>78</td>\n",
       "      <td>8</td>\n",
       "      <td>3198</td>\n",
       "      <td>857</td>\n",
       "      <td>97</td>\n",
       "      <td>470</td>\n",
       "      <td>420</td>\n",
       "      <td>332</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>1314</td>\n",
       "      <td>131</td>\n",
       "      <td>12</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>631</td>\n",
       "      <td>170</td>\n",
       "      <td>9</td>\n",
       "      <td>77</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>4908</td>\n",
       "      <td>1457</td>\n",
       "      <td>30</td>\n",
       "      <td>775</td>\n",
       "      <td>357</td>\n",
       "      <td>249</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>408</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>322 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AtBat  Hits  HmRun  Runs  ...  Assists  Errors       Salary  NewLeague\n",
       "0      293    66      1    30  ...       33      20   535.925882          A\n",
       "1      315    81      7    24  ...       43      10   475.000000          N\n",
       "2      479   130     18    66  ...       82      14   480.000000          A\n",
       "3      496   141     20    65  ...       11       3   500.000000          N\n",
       "4      321    87     10    39  ...       40       4    91.500000          N\n",
       "..     ...   ...    ...   ...  ...      ...     ...          ...        ...\n",
       "317    497   127      7    65  ...        9       3   700.000000          N\n",
       "318    492   136      5    76  ...      381      20   875.000000          A\n",
       "319    475   126      3    61  ...      113       7   385.000000          A\n",
       "320    573   144      9    85  ...      131      12   960.000000          A\n",
       "321    631   170      9    77  ...        4       3  1000.000000          A\n",
       "\n",
       "[322 rows x 20 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace missing salary data with average\n",
    "hitters['Salary'].fillna(hitters['Salary'].mean(), inplace=True)\n",
    "hitters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Different Model Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRuns: 429.1188810776027\n",
      "AtBat: -310.8336994660927\n",
      "CAtBat: -309.7234513025987\n",
      "Hits: 286.9220505971286\n",
      "CRBI: 210.89251515025924\n",
      "CWalks: -177.75371266019405\n",
      "Walks: 113.77095895125693\n",
      "CHits: 92.0584551351487\n",
      "PutOuts: 65.70063996330718\n",
      "Division_W: -55.50379454676699\n",
      "CRuns: 429.1188810776027\n",
      "AtBat: -310.8336994660927\n",
      "CAtBat: -309.7234513025987\n",
      "Hits: 286.9220505971286\n",
      "CRBI: 210.89251515025924\n",
      "CWalks: -177.75371266019405\n",
      "Walks: 113.77095895125693\n",
      "CHits: 92.0584551351487\n",
      "PutOuts: 65.70063996330718\n",
      "Division_W: -55.50379454676699\n"
     ]
    }
   ],
   "source": [
    "# Define X and y\n",
    "X = hitters.drop(\"Salary\", axis=1)\n",
    "y = hitters[\"Salary\"]\n",
    "\n",
    "# CT\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"one_hot\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"),\n",
    "         make_column_selector(dtype_include=object)),\n",
    "        (\"scale\", StandardScaler(),\n",
    "         make_column_selector(dtype_include=np.number))\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Create the linear regression pipeline\n",
    "lr_pipeline = Pipeline([\n",
    "    (\"preprocessing\", ct),\n",
    "    (\"lr\", lr)\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the full dataset\n",
    "lr_pipeline.fit(X, y)\n",
    "\n",
    "# Get coefficients\n",
    "lr_coef = lr_pipeline.named_steps['lr'].coef_\n",
    "\n",
    "# Get feature names from transformed data\n",
    "cat_features = ct.named_transformers_[\"one_hot\"].get_feature_names_out(input_features=X.select_dtypes(include=object).columns)\n",
    "num_features = X.select_dtypes(include=np.number).columns\n",
    "feature_names = np.concatenate([cat_features, num_features])\n",
    "\n",
    "# Pair features with coefficients and most important ones by size\n",
    "feature_coefficients = list(zip(feature_names, lr_coef))\n",
    "sorted_coefficients = sorted(feature_coefficients, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Display most significant coefficients\n",
    "for feature, coef in sorted_coefficients[:10]:\n",
    "    print(f\"{feature}: {coef}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each run in a player’s career increases salary by about $429.12, which suggests that players who score more runs are highly valued.\n",
    "\n",
    "Each at bat in the season decreases salary by approximately $310.83, which means that having a high number of at bats without standout performance might not contribute positively to salary.\n",
    "\n",
    "Similar to AtBat, each career at bat reduces salary by about $310, which suggest that quantity alone doesn’t drive salary increases.\n",
    "\n",
    "Each  hit in the season increases salary by about $286.92. This highlights the importance of effective batting performance in determining salary.\n",
    "\n",
    "Each additional career RBI in a player’s career increases salary by about $210.89, showing that players with a track record of driving in runs tend to have higher salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Cross-Validated MSE: 111079.9589401905\n",
      "Estimated Cross-Validated MSE: 111079.9589401905\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation to estimate MSE\n",
    "mse_scores = -cross_val_score(lr_pipeline, X, y, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "mean_mse = np.mean(mse_scores)\n",
    "\n",
    "print(\"Estimated Cross-Validated MSE:\", mean_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   alphas         scores\n",
      "0   0.001  110827.268479\n",
      "1   0.010  110706.903449\n",
      "2   0.100  109843.994208\n",
      "3   1.000  107961.775111\n",
      "4  10.000  108447.788605\n",
      "   alphas         scores\n",
      "0   0.001  110827.268479\n",
      "1   0.010  110706.903449\n",
      "2   0.100  109843.994208\n",
      "3   1.000  107961.775111\n",
      "4  10.000  108447.788605\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge()\n",
    "\n",
    "# Set up the Ridge regression pipeline\n",
    "ridge_pipeline = Pipeline([\n",
    "    (\"preprocessing\", ct),\n",
    "    (\"ridge_regression\", ridge)\n",
    "])\n",
    "\n",
    "# Range of lambda values to search\n",
    "alpha = {\"ridge_regression__alpha\": [0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "# Perform grid search cross-validation\n",
    "gscv_ridge = GridSearchCV(ridge_pipeline, alpha, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "ridge_fitted = gscv_ridge.fit(X, y)\n",
    "\n",
    "# Convert MSE scores to positive values for readability\n",
    "positive_mse_scores = -ridge_fitted.cv_results_[\"mean_test_score\"]\n",
    "\n",
    "# Display alpha values and corresponding MSE scores\n",
    "results_df = pd.DataFrame({\n",
    "    \"alphas\": alpha[\"ridge_regression__alpha\"],\n",
    "    \"scores\": positive_mse_scores\n",
    "})\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictors</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CRuns</td>\n",
       "      <td>308.502312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AtBat</td>\n",
       "      <td>-291.999497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hits</td>\n",
       "      <td>254.470866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CAtBat</td>\n",
       "      <td>-192.812729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CWalks</td>\n",
       "      <td>-155.856907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CRBI</td>\n",
       "      <td>132.055392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CHits</td>\n",
       "      <td>128.640891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Walks</td>\n",
       "      <td>106.083069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Years</td>\n",
       "      <td>-67.889011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PutOuts</td>\n",
       "      <td>65.577334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predictors  Coefficient\n",
       "16      CRuns   308.502312\n",
       "6       AtBat  -291.999497\n",
       "7        Hits   254.470866\n",
       "13     CAtBat  -192.812729\n",
       "18     CWalks  -155.856907\n",
       "17       CRBI   132.055392\n",
       "14      CHits   128.640891\n",
       "11      Walks   106.083069\n",
       "12      Years   -67.889011\n",
       "19    PutOuts    65.577334"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get best pipeline from grid search\n",
    "best_ridge_model = ridge_fitted.best_estimator_\n",
    "\n",
    "# Get coefficients from the Ridge regression model\n",
    "ridge_coef = best_ridge_model.named_steps[\"ridge_regression\"].coef_\n",
    "\n",
    "# Ensure the correct transformer name is used to access categorical feature names\n",
    "cat_features = best_ridge_model.named_steps[\"preprocessing\"].named_transformers_[\"one_hot\"].get_feature_names_out(\n",
    "    input_features=X.select_dtypes(include=object).columns\n",
    ")\n",
    "num_features = X.select_dtypes(include=np.number).columns\n",
    "variables = list(cat_features) + list(num_features)\n",
    "\n",
    "# Create DataFrame to display feature names and coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    \"Predictors\": variables,\n",
    "    \"Coefficient\": ridge_coef\n",
    "})\n",
    "\n",
    "# Sort coefficients by absolute value for importance\n",
    "coef_df = coef_df.reindex(coef_df['Coefficient'].abs().sort_values(ascending=False).index)\n",
    "\n",
    "coef_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each career run, salary increases by about $308.50.\n",
    "\n",
    "For each at-bat during the season, salary is decreased by $292.\n",
    "\n",
    "For each hit in the season, it is associated with an increase in salary by around $254.47.\n",
    "\n",
    "For each career at-bat, it is associated with a decrease in salary of about $193.81.\n",
    "\n",
    "For each career walk, it is correlated with a decrease in salary by about $156.86."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected MSE for predicting 1989 salaries: 107961.77511144585\n",
      "Expected MSE for predicting 1989 salaries: 107961.77511144585\n"
     ]
    }
   ],
   "source": [
    "# Get best cross-validated MSE from the grid search\n",
    "print(\"Expected MSE for predicting 1989 salaries:\", -ridge_fitted.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.180e+07, tolerance: 4.773e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.065e+07, tolerance: 3.665e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+07, tolerance: 4.051e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.598e+06, tolerance: 4.314e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+07, tolerance: 4.496e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.779e+06, tolerance: 4.773e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.194e+06, tolerance: 3.665e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.990e+06, tolerance: 4.051e+03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.980e+06, tolerance: 4.314e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.740e+06, tolerance: 4.496e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.850e+04, tolerance: 4.773e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.308e+05, tolerance: 3.665e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.889e+05, tolerance: 4.051e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.058e+05, tolerance: 4.314e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+06, tolerance: 4.496e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.423e+03, tolerance: 4.773e+03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.495e+03, tolerance: 4.314e+03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results for Alpha Values in Lasso Regression:\n",
      "   alphas         scores\n",
      "0   0.001  110587.805496\n",
      "1   0.010  110543.622361\n",
      "2   0.100  110095.047688\n",
      "3   1.000  108120.277446\n",
      "4  10.000  112995.351102\n",
      "Cross-Validation Results for Alpha Values in Lasso Regression:\n",
      "   alphas         scores\n",
      "0   0.001  110587.805496\n",
      "1   0.010  110543.622361\n",
      "2   0.100  110095.047688\n",
      "3   1.000  108120.277446\n",
      "4  10.000  112995.351102\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "\n",
    "# Set up the Lasso regression pipeline\n",
    "lasso_pipeline = Pipeline([\n",
    "    (\"preprocessing\", ct),\n",
    "    (\"lasso_regression\", lasso)\n",
    "])\n",
    "\n",
    "# Perform grid search cross-validation to find the best alpha\n",
    "gscv_lasso = GridSearchCV(lasso_pipeline, alpha, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "lasso_fitted = gscv_lasso.fit(X, y)\n",
    "\n",
    "# Convert MSE scores to positive values for readability\n",
    "positive_mse_scores = -lasso_fitted.cv_results_[\"mean_test_score\"]\n",
    "\n",
    "# Display alpha values and corresponding MSE scores\n",
    "results_df = pd.DataFrame({\n",
    "    \"alphas\": alpha[\"lasso_regression__alpha\"],\n",
    "    \"scores\": positive_mse_scores\n",
    "})\n",
    "\n",
    "print(\"Cross-Validation Results for Alpha Values in Lasso Regression:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictors</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CRuns</td>\n",
       "      <td>322.919372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AtBat</td>\n",
       "      <td>-301.965077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hits</td>\n",
       "      <td>268.257422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CWalks</td>\n",
       "      <td>-159.303481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CRBI</td>\n",
       "      <td>129.397762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Division_E</td>\n",
       "      <td>111.335545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Walks</td>\n",
       "      <td>103.905910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Years</td>\n",
       "      <td>-71.479936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CAtBat</td>\n",
       "      <td>-66.681811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PutOuts</td>\n",
       "      <td>65.935549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predictors  Coefficient\n",
       "16       CRuns   322.919372\n",
       "6        AtBat  -301.965077\n",
       "7         Hits   268.257422\n",
       "18      CWalks  -159.303481\n",
       "17        CRBI   129.397762\n",
       "2   Division_E   111.335545\n",
       "11       Walks   103.905910\n",
       "12       Years   -71.479936\n",
       "13      CAtBat   -66.681811\n",
       "19     PutOuts    65.935549"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = lasso_pipeline.named_steps[\"preprocessing\"].named_transformers_[\"one_hot\"].get_feature_names_out(\n",
    "    input_features=X.select_dtypes(include=object).columns\n",
    ")\n",
    "num_features = X.select_dtypes(include=np.number).columns\n",
    "var_names = list(cat_features) + list(num_features)\n",
    "\n",
    "# Get the best model's coefficients\n",
    "lasso_coef = lasso_fitted.best_estimator_.named_steps[\"lasso_regression\"].coef_\n",
    "\n",
    "# Create a DataFrame to display feature names and corresponding coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    \"Predictors\": var_names,\n",
    "    \"Coefficient\": lasso_coef\n",
    "})\n",
    "\n",
    "# Sort coefficients by absolute value for importance\n",
    "coef_df = coef_df.reindex(coef_df['Coefficient'].abs().sort_values(ascending=False).index)\n",
    "\n",
    "coef_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each career run, salary increases by about $322.92.\n",
    "\n",
    "For each at bat, salary decreases by -$301.97.\n",
    "\n",
    "For each hit in the season, salary increases by $268.26\n",
    "\n",
    "For each career walk, salary decreaes by -$159.30\n",
    "\n",
    "For each career RBI, salary increases by $129.40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected MSE for predicting 1989 salaries: 108120.27744636913\n",
      "Expected MSE for predicting 1989 salaries: 108120.27744636913\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected MSE for predicting 1989 salaries:\", -lasso_fitted.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>109065.903872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.05</td>\n",
       "      <td>109102.918082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>109151.297555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>109372.345404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>109650.866038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>110013.253075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>110509.504781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.95</td>\n",
       "      <td>110663.988730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.99</td>\n",
       "      <td>110798.979559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>107620.139087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>107622.820551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>107628.386976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>107682.044013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>107816.277799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.7</td>\n",
       "      <td>108124.175844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>109033.839902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.95</td>\n",
       "      <td>109623.189062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>110454.658483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>109897.050432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>109829.215366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>109740.082061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>109328.290777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>108804.089860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>108148.475768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>107595.016411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>107771.641741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>108803.780096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>113775.302139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>113676.992694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>113552.173790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>113023.117890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>112467.192491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>111749.674793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>110052.266158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>109003.475514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>107546.193492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>131904.500436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>131355.458409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>130644.381601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>127499.329762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>123826.676915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "      <td>119625.937229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10</td>\n",
       "      <td>0.9</td>\n",
       "      <td>114812.475190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10</td>\n",
       "      <td>0.95</td>\n",
       "      <td>113290.608743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>112067.082789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha l1_ratio            MSE\n",
       "0   0.001     0.01  109065.903872\n",
       "1   0.001     0.05  109102.918082\n",
       "2   0.001      0.1  109151.297555\n",
       "3   0.001      0.3  109372.345404\n",
       "4   0.001      0.5  109650.866038\n",
       "5   0.001      0.7  110013.253075\n",
       "6   0.001      0.9  110509.504781\n",
       "7   0.001     0.95  110663.988730\n",
       "8   0.001     0.99  110798.979559\n",
       "9    0.01     0.01  107620.139087\n",
       "10   0.01     0.05  107622.820551\n",
       "11   0.01      0.1  107628.386976\n",
       "12   0.01      0.3  107682.044013\n",
       "13   0.01      0.5  107816.277799\n",
       "14   0.01      0.7  108124.175844\n",
       "15   0.01      0.9  109033.839902\n",
       "16   0.01     0.95  109623.189062\n",
       "17   0.01     0.99  110454.658483\n",
       "18    0.1     0.01  109897.050432\n",
       "19    0.1     0.05  109829.215366\n",
       "20    0.1      0.1  109740.082061\n",
       "21    0.1      0.3  109328.290777\n",
       "22    0.1      0.5  108804.089860\n",
       "23    0.1      0.7  108148.475768\n",
       "24    0.1      0.9  107595.016411\n",
       "25    0.1     0.95  107771.641741\n",
       "26    0.1     0.99  108803.780096\n",
       "27      1     0.01  113775.302139\n",
       "28      1     0.05  113676.992694\n",
       "29      1      0.1  113552.173790\n",
       "30      1      0.3  113023.117890\n",
       "31      1      0.5  112467.192491\n",
       "32      1      0.7  111749.674793\n",
       "33      1      0.9  110052.266158\n",
       "34      1     0.95  109003.475514\n",
       "35      1     0.99  107546.193492\n",
       "36     10     0.01  131904.500436\n",
       "37     10     0.05  131355.458409\n",
       "38     10      0.1  130644.381601\n",
       "39     10      0.3  127499.329762\n",
       "40     10      0.5  123826.676915\n",
       "41     10      0.7  119625.937229\n",
       "42     10      0.9  114812.475190\n",
       "43     10     0.95  113290.608743\n",
       "44     10     0.99  112067.082789"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the Elastic Net pipeline\n",
    "elastic_pipeline = Pipeline(\n",
    "    [(\"preprocessing\", ct),\n",
    "     (\"elastic_net\", ElasticNet(max_iter=10000))]\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "# Define lambda and l1_ratio\n",
    "alphas = {\n",
    "    \"elastic_net__alpha\": [0.001, 0.01, 0.1, 1, 10],\n",
    "    \"elastic_net__l1_ratio\": [0.01, 0.05, 0.1, 0.3, 0.5, 0.7, 0.9, 0.95, 0.99]\n",
    "}\n",
    "\n",
    "# Perform grid search cross-validation\n",
    "gscv_elastic = GridSearchCV(elastic_net_regression, alphas, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "elastic_fitted = gscv_elastic.fit(X, y)\n",
    "\n",
    "# Convert MSE scores to positive values for readability\n",
    "positive_mse_scores = -elastic_fitted.cv_results_[\"mean_test_score\"]\n",
    "\n",
    "# Display alpha and l1_ratio with corresponding MSE scores\n",
    "results_df = pd.DataFrame({\n",
    "    \"alpha\": elastic_fitted.cv_results_[\"param_elastic_net__alpha\"],\n",
    "    \"l1_ratio\": elastic_fitted.cv_results_[\"param_elastic_net__l1_ratio\"],\n",
    "    \"MSE\": positive_mse_scores\n",
    "})\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictors</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AtBat</td>\n",
       "      <td>-220.715293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hits</td>\n",
       "      <td>190.588113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CRuns</td>\n",
       "      <td>181.655518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CWalks</td>\n",
       "      <td>-110.208856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Walks</td>\n",
       "      <td>87.602756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CRBI</td>\n",
       "      <td>82.882795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CHits</td>\n",
       "      <td>79.361123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Years</td>\n",
       "      <td>-77.460591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PutOuts</td>\n",
       "      <td>63.822676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Division_W</td>\n",
       "      <td>-57.211874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predictors  Coefficient\n",
       "6        AtBat  -220.715293\n",
       "7         Hits   190.588113\n",
       "16       CRuns   181.655518\n",
       "18      CWalks  -110.208856\n",
       "11       Walks    87.602756\n",
       "17        CRBI    82.882795\n",
       "14       CHits    79.361123\n",
       "12       Years   -77.460591\n",
       "19     PutOuts    63.822676\n",
       "3   Division_W   -57.211874"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get best parameters and fit the pipeline with optimized hyperparameters\n",
    "best_alpha = elastic_fitted.best_params_[\"elastic_net__alpha\"]\n",
    "best_l1_ratio = elastic_fitted.best_params_[\"elastic_net__l1_ratio\"]\n",
    "\n",
    "elastic_pipeline.set_params(\n",
    "    elastic_net__alpha=best_alpha,\n",
    "    elastic_net__l1_ratio=best_l1_ratio\n",
    ")\n",
    "elastic_pipeline.fit(X, y)\n",
    "\n",
    "# Retrieve feature names and coefficients from the best model\n",
    "cat_features = elastic_pipeline.named_steps[\"preprocessing\"].named_transformers_[\"one_hot\"].get_feature_names_out(\n",
    "    input_features=X.select_dtypes(include=object).columns\n",
    ")\n",
    "num_features = X.select_dtypes(include=np.number).columns\n",
    "variables = list(cat_features) + list(num_features)\n",
    "elastic_net_coef = elastic_pipeline.named_steps[\"elastic_net\"].coef_\n",
    "\n",
    "# Display most significant coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    \"Predictors\": variables,\n",
    "    \"Coefficient\": elastic_net_coef\n",
    "})\n",
    "\n",
    "# Sort coefficients by absolute value for significance\n",
    "coef_df = coef_df.reindex(coef_df['Coefficient'].abs().sort_values(ascending=False).index)\n",
    "\n",
    "coef_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each at bat, salary decreases by -$220.72\n",
    "\n",
    "For each hit during the season, salary increases by $190.59\n",
    "\n",
    "For each career runs, salary increases by $181.66\n",
    "\n",
    "For each career walks, salary decreases by -$110.21\n",
    "\n",
    "For each walks during the season, salary increases by $87.60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected MSE for predicting 1989 salaries with Elastic Net: 107546.19349237923\n",
      "Expected MSE for predicting 1989 salaries with Elastic Net: 107546.19349237923\n"
     ]
    }
   ],
   "source": [
    "# MSE for predicting 1989 salaries\n",
    "print(\"Expected MSE for predicting 1989 salaries with Elastic Net:\", -elastic_fitted.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Variable Selection\n",
    "Based on the above results, decide on:\n",
    "\n",
    "Which numeric variable is most important.\n",
    "CRuns\n",
    "\n",
    "Which five numeric variables are most important\n",
    "CRuns, AtBat, CAtBat, Hits, CRBI\n",
    "\n",
    "Which categorical variable is most important\n",
    "Division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the four model specifications, compare the following possible feature sets:\n",
    "\n",
    "Using only the one best numeric variable.\n",
    "\n",
    "Using only the five best variables.\n",
    "\n",
    "Using the five best numeric variables and their interactions with the one best categorical variable.\n",
    "\n",
    "Report which combination of features and model performed best, based on the validation metric of MSE.\n",
    "\n",
    "(Note: $\\lambda$ and $\\alpha$ must be re-tuned for each feature set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Define Column Transformer for Dummies and Scaling\n",
    "def create_column_transformer():\n",
    "    return ColumnTransformer([\n",
    "        (\"one_hot\", OneHotEncoder(sparse_output=False, handle_unknown='ignore'), make_column_selector(dtype_include=object)),\n",
    "        (\"scale\", StandardScaler(), make_column_selector(dtype_include=np.number))\n",
    "    ], remainder=\"passthrough\").set_output(transform=\"pandas\")\n",
    "\n",
    "# Interaction Transformer based on feature data\n",
    "def create_interaction_transformer(feature_data):\n",
    "    interaction_columns = {\n",
    "        'Hits': 'scale__Hits', \n",
    "        'PutOuts': 'scale__PutOuts', \n",
    "        'Walks': 'scale__Walks', \n",
    "        'CRBI': 'scale__CRBI', \n",
    "        'CRuns': 'scale__CRuns',\n",
    "        'Division_E': 'one_hot__Division_E'\n",
    "    }\n",
    "    \n",
    "    available_interactions = [\n",
    "        (name, PolynomialFeatures(interaction_only=True, include_bias=False), [interaction_columns[col] for col in cols])\n",
    "        for name, cols in {\n",
    "            'hits_division': ['Hits', 'Division_E'],\n",
    "            'putouts_division': ['PutOuts', 'Division_E'],\n",
    "            'walks_division': ['Walks', 'Division_E'],\n",
    "            'crbi_division': ['CRBI', 'Division_E'],\n",
    "            'cruns_division': ['CRuns', 'Division_E']\n",
    "        }.items() if all(col in feature_data.columns for col in cols)\n",
    "    ]\n",
    "    \n",
    "    return ColumnTransformer(available_interactions, remainder=\"passthrough\").set_output(transform=\"pandas\")\n",
    "\n",
    "# Base column transformer\n",
    "ct = create_column_transformer()\n",
    "\n",
    "# Function to calculate MSE\n",
    "def get_mse(model, feature_data, target, alpha=None, l1_ratio=None):\n",
    "    # Set alpha or lambda if provided\n",
    "    if isinstance(model, Ridge) or isinstance(model, Lasso):\n",
    "        model.set_params(alpha=alpha)\n",
    "    elif isinstance(model, ElasticNet):\n",
    "        model.set_params(alpha=alpha, l1_ratio=l1_ratio)\n",
    "\n",
    "    pipeline = Pipeline([(\"preprocess\", ct), (\"model\", model)])\n",
    "    \n",
    "    # Calculate and return MSE from cross-validation\n",
    "    mse_scores = cross_val_score(pipeline, feature_data, target, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "    mse = -mse_scores.mean()\n",
    "    print(f\"Cross-validated MSE for {model.__class__.__name__}: {mse}\")\n",
    "    return mse\n",
    "\n",
    "# Function for Hyperparameter Tuning with Interactions\n",
    "def tune_with_interactions(model, feature_data, target):\n",
    "    # Set up the interaction transformer if multiple features\n",
    "    if feature_data.shape[1] > 1:\n",
    "        interaction_transformer = create_interaction_transformer(feature_data)\n",
    "        pipeline = Pipeline([\n",
    "            (\"preprocess\", ct),\n",
    "            (\"interactions\", interaction_transformer),\n",
    "            (\"model\", model)\n",
    "        ])\n",
    "    else:\n",
    "        pipeline = Pipeline([\n",
    "            (\"preprocess\", ct),\n",
    "            (\"model\", model)\n",
    "        ])\n",
    "    \n",
    "    # Define separate grids for each model type\n",
    "    if isinstance(model, ElasticNet):\n",
    "        param_grid = {'model__alpha': [0.001, 0.01, 0.1, 1, 10], 'model__l1_ratio': [0.1, 0.5, 0.9]}\n",
    "    else:\n",
    "        param_grid = {'model__alpha': [0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2')\n",
    "    grid_search.fit(feature_data, target)\n",
    "\n",
    "    # Extract best parameters\n",
    "    best_params = {\n",
    "        \"alpha\": grid_search.best_params_['model__alpha'],\n",
    "        \"l1_ratio\": grid_search.best_params_.get('model__l1_ratio', None)\n",
    "    }\n",
    "    best_score = grid_search.best_score_\n",
    "    print(f\"Tuned results for {model.__class__.__name__}: Alpha: {best_params['alpha']}, L1 Ratio: {best_params['l1_ratio']}, R2: {best_score}\")\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated MSE for LinearRegression: 126308.142061745\n",
      "Cross-validated MSE for LinearRegression: 126308.142061745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "126308.142061745"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best numeric variable as predictor\n",
    "\n",
    "# Specifying X \n",
    "X = hitters[['CRuns']]  \n",
    "\n",
    "# Calculate MSE for Linear Regression using the best numeric variable\n",
    "get_mse(LinearRegression(), feature_data=X, target=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated MSE for LinearRegression: 110613.63340859996\n",
      "Cross-validated MSE for LinearRegression: 110613.63340859996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "110613.63340859996"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 best numeric variable as predictor\n",
    "\n",
    "# Specifying X\n",
    "X = hitters[['CRuns', 'AtBat', 'CAtBat', 'Hits', 'CRBI']]  \n",
    "\n",
    "# Calculate MSE for Linear Regression using the best numeric variable\n",
    "get_mse(LinearRegression(), feature_data=X, target=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated MSE for LinearRegression: 111083.23832786758\n",
      "Cross-validated MSE for LinearRegression: 111083.23832786758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "111083.23832786758"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 best numeric variables and interactions with best categorical variable\n",
    "\n",
    "X = hitters[['CRuns','CRBI', 'Hits', 'PutOuts', 'Walks','Division']]\n",
    "\n",
    "get_mse(LinearRegression(), feature_data=X, target=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned results for Ridge: Alpha: 10, L1 Ratio: None, R2: 0.2319901518881867\n",
      "Best Lambda Value: 10.0\n",
      "Cross-validated MSE for Ridge: 126265.14518438917\n",
      "Tuned results for Ridge: Alpha: 10, L1 Ratio: None, R2: 0.2319901518881867\n",
      "Best Lambda Value: 10.0\n",
      "Cross-validated MSE for Ridge: 126265.14518438917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "126265.14518438917"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best numeric variable as predictor\n",
    "\n",
    "X = hitters[['CRuns']]  \n",
    "\n",
    "# Tuning for Feature Set\n",
    "best_lambda = float(tune_with_interactions(Ridge(), feature_data=X, target=y)['alpha'])\n",
    "print(\"Best Lambda Value:\", best_lambda)\n",
    "\n",
    "# Calculate MSE using the best lambda value\n",
    "get_mse(Ridge(), feature_data=X, target=y, alpha=best_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned results for Ridge: Alpha: 1, L1 Ratio: None, R2: 0.3081315321451029\n",
      "Best Lambda Value: 1.0\n",
      "Cross-validated MSE for Ridge: 110629.01564902542\n",
      "Tuned results for Ridge: Alpha: 1, L1 Ratio: None, R2: 0.3081315321451029\n",
      "Best Lambda Value: 1.0\n",
      "Cross-validated MSE for Ridge: 110629.01564902542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "110629.01564902542"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 best numeric variables\n",
    "\n",
    "X = hitters[['CRuns', 'AtBat', 'CAtBat', 'Hits', 'CRBI']]  \n",
    "\n",
    "# Tuning for Feature Set\n",
    "best_lambda = float(tune_with_interactions(Ridge(), feature_data=X, target=y)['alpha'])\n",
    "print(\"Best Lambda Value:\", best_lambda)\n",
    "\n",
    "# Calculate MSE using the best lambda value\n",
    "get_mse(Ridge(), feature_data=X, target=y, alpha=best_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned results for Ridge: Alpha: 1, L1 Ratio: None, R2: 0.31028339381417425\n",
      "Best Lambda Value: 1.0\n",
      "Cross-validated MSE for Ridge: 108535.39377820064\n",
      "Tuned results for Ridge: Alpha: 1, L1 Ratio: None, R2: 0.31028339381417425\n",
      "Best Lambda Value: 1.0\n",
      "Cross-validated MSE for Ridge: 108535.39377820064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "108535.39377820064"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 best numeric variables and interactions with best categorical variable\n",
    "\n",
    "X = hitters[['CRuns', 'AtBat', 'CAtBat', 'Hits', 'CRBI', 'Division']]  \n",
    "\n",
    "# Tuning for Feature Set\n",
    "best_lambda = float(tune_with_interactions(Ridge(), feature_data=X, target=y)['alpha'])\n",
    "print(\"Best Lambda Value:\", best_lambda)\n",
    "\n",
    "# Calculate MSE using the best lambda value\n",
    "get_mse(Ridge(), feature_data=X, target=y, alpha=best_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Function to calculate MSE with preprocessed data\n",
    "def get_mse(model, X_transformed, y, alpha=None):\n",
    "    if alpha is not None:\n",
    "        model.set_params(alpha=alpha)\n",
    "    pipeline = Pipeline([(\"model\", model)])\n",
    "    mse_scores = cross_val_score(pipeline, X_transformed, y, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "    mse = -mse_scores.mean()\n",
    "    print(f\"Cross-validated MSE for {model.__class__.__name__}: {mse}\")\n",
    "    return mse\n",
    "\n",
    "# Tuning function for Lasso model with preprocessed data\n",
    "def tune_with_lasso(model, X_transformed, y):\n",
    "    pipeline = Pipeline([(\"model\", model)])\n",
    "    param_grid = {'model__alpha': [0.001, 0.01, 0.1, 1, 10]}\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2')\n",
    "    grid_search.fit(X_transformed, y)\n",
    "    best_alpha = grid_search.best_params_['model__alpha']\n",
    "    print(f\"Best Alpha for Lasso: {best_alpha}, R2: {grid_search.best_score_}\")\n",
    "    return best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha for Lasso: 0.1, R2: 0.3092802178087622\n",
      "Cross-validated MSE for Lasso: 108525.46164164218\n",
      "Best Alpha for Lasso: 0.1, R2: 0.3092802178087622\n",
      "Cross-validated MSE for Lasso: 108525.46164164218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "108525.46164164218"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best numeric variable as predictor\n",
    "\n",
    "X = hitters[['CRuns']]  \n",
    "\n",
    "# Tuning for Feature Set\n",
    "best_lambda = tune_with_lasso(Lasso(), X_transformed, y)\n",
    "get_mse(Lasso(alpha=best_lambda), X_transformed, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha for Lasso: 0.1, R2: 0.3092802178087622\n",
      "Cross-validated MSE for Lasso: 108525.46164164218\n",
      "Best Alpha for Lasso: 0.1, R2: 0.3092802178087622\n",
      "Cross-validated MSE for Lasso: 108525.46164164218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "108525.46164164218"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 best numeric variables \n",
    "X = hitters[['CRuns', 'AtBat', 'CAtBat', 'Hits', 'CRBI']]  \n",
    "\n",
    "# Tuning for Feature Set\n",
    "best_lambda = tune_with_lasso(Lasso(), X_transformed, y)\n",
    "get_mse(Lasso(alpha=best_lambda), X_transformed, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha for Lasso: 0.1, R2: 0.3092802178087622\n",
      "Cross-validated MSE for Lasso: 108525.46164164218\n",
      "Best Alpha for Lasso: 0.1, R2: 0.3092802178087622\n",
      "Cross-validated MSE for Lasso: 108525.46164164218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "108525.46164164218"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 best numeric variables and interactions with best categorical variable\n",
    "X = hitters[['CRuns', 'AtBat', 'CAtBat', 'Hits', 'CRBI','Division']]  \n",
    "\n",
    "# Tuning for Feature Set\n",
    "best_lambda = tune_with_lasso(Lasso(), X_transformed, y)\n",
    "get_mse(Lasso(alpha=best_lambda), X_transformed, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned results for ElasticNet: Alpha: 0.1, L1 Ratio: 0.1, R2: 0.23219409390951898\n",
      "Best Lambda Value (alpha): 0.1\n",
      "Best L1 Ratio: 0.1\n",
      "Cross-validated MSE for ElasticNet: 126377.44450764442\n",
      "Tuned results for ElasticNet: Alpha: 0.1, L1 Ratio: 0.1, R2: 0.23219409390951898\n",
      "Best Lambda Value (alpha): 0.1\n",
      "Best L1 Ratio: 0.1\n",
      "Cross-validated MSE for ElasticNet: 126377.44450764442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "126377.44450764442"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best numeric variable \n",
    "X = hitters[['CRuns']]\n",
    "\n",
    "# Re-tuning with Feature Set\n",
    "best_params = tune_with_interactions(ElasticNet(), feature_data=X, target=y)\n",
    "best_lambda = best_params['alpha']\n",
    "best_l1_ratio = best_params['l1_ratio']\n",
    "\n",
    "print(\"Best Lambda Value (alpha):\", best_lambda)\n",
    "print(\"Best L1 Ratio:\", best_l1_ratio)\n",
    "\n",
    "# Calculate MSE using the best lambda (alpha) and l1_ratio\n",
    "get_mse(ElasticNet(alpha=best_lambda, l1_ratio=best_l1_ratio), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned results for ElasticNet: Alpha: 0.01, L1 Ratio: 0.5, R2: 0.308124825578613\n",
      "Best Lambda Value (alpha): 0.01\n",
      "Best L1 Ratio: 0.5\n",
      "Cross-validated MSE for ElasticNet: 110697.9873733443\n",
      "Tuned results for ElasticNet: Alpha: 0.01, L1 Ratio: 0.5, R2: 0.308124825578613\n",
      "Best Lambda Value (alpha): 0.01\n",
      "Best L1 Ratio: 0.5\n",
      "Cross-validated MSE for ElasticNet: 110697.9873733443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "110697.9873733443"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 best numeric variables \n",
    "X = hitters[['CRuns', 'AtBat', 'CAtBat', 'Hits', 'CRBI']]  \n",
    "\n",
    "# Re-tuning with Feature Set\n",
    "best_params = tune_with_interactions(ElasticNet(), feature_data=X, target=y)\n",
    "best_lambda = best_params['alpha']\n",
    "best_l1_ratio = best_params['l1_ratio']\n",
    "\n",
    "print(\"Best Lambda Value (alpha):\", best_lambda)\n",
    "print(\"Best L1 Ratio:\", best_l1_ratio)\n",
    "\n",
    "# Calculate MSE using the best lambda (alpha) and l1_ratio\n",
    "get_mse(ElasticNet(alpha=best_lambda, l1_ratio=best_l1_ratio), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.907e+06, tolerance: 4.773e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.013e+07, tolerance: 4.773e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.999e+06, tolerance: 3.665e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.391e+06, tolerance: 4.051e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.022e+06, tolerance: 4.314e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.996e+06, tolerance: 4.496e+03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned results for ElasticNet: Alpha: 0.01, L1 Ratio: 0.5, R2: 0.310175472229846\n",
      "Best Lambda Value (alpha): 0.01\n",
      "Best L1 Ratio: 0.5\n",
      "Cross-validated MSE for ElasticNet: 108595.47006031669\n",
      "Tuned results for ElasticNet: Alpha: 0.01, L1 Ratio: 0.5, R2: 0.310175472229846\n",
      "Best Lambda Value (alpha): 0.01\n",
      "Best L1 Ratio: 0.5\n",
      "Cross-validated MSE for ElasticNet: 108595.47006031669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "108595.47006031669"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 best numeric variables and interactions with best categorical variable\n",
    "X = hitters[['CRuns', 'AtBat', 'CAtBat', 'Hits', 'CRBI','Division']] \n",
    "\n",
    "# Re-tuning with Feature Set\n",
    "best_params = tune_with_interactions(ElasticNet(), feature_data=X, target=y)\n",
    "best_lambda = best_params['alpha']\n",
    "best_l1_ratio = best_params['l1_ratio']\n",
    "\n",
    "print(\"Best Lambda Value (alpha):\", best_lambda)\n",
    "print(\"Best L1 Ratio:\", best_l1_ratio)\n",
    "\n",
    "# Calculate MSE using the best lambda (alpha) and l1_ratio\n",
    "get_mse(ElasticNet(alpha=best_lambda, l1_ratio=best_l1_ratio), X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso with the 5 best numeric variables and the interaction with the best categorical variable performed the best because it has the lowest MSE of 108524.76569799737"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Ridge\n",
    "Compare your Ridge models with your ordinary regression models. How did your coefficients compare? Why does this make sense?\n",
    "\n",
    "Ridge models have smaller coefficients compared to linear regression models. This makes sense because Ridge regression includes a penalty on the size of the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. LASSO\n",
    "Compare your LASSO model in I with your three LASSO models in II. Did you get the same $\\lambda$ results? Why does this make sense? Did you get the same MSEs? Why does this make sense?\n",
    "\n",
    "Yes $\\lambda$ are all the same. This makes sense because because we used a consistent hyperparameter tuning process with cross-validation. However, the MSEs are slightly different because of the different amounts of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Elastic Net\n",
    "Compare your MSEs for the Elastic Net models with those for the Ridge and LASSO models. Why does it make sense that Elastic Net always “wins”?\n",
    "\n",
    "Elastic Net models always \"wins\" with the lowest MSE because it combines characteristics from both Ridge and LASSO models. This allows Elastic Net models to handle multicollinearity while selecting the most important predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV: Final Model\n",
    "Fit your final best pipeline on the full dataset, and summarize your results in a few short sentences and a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.866e+06, tolerance: 4.773e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.903e+05, tolerance: 3.665e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.486e+05, tolerance: 4.314e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.360e+06, tolerance: 4.496e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e+07, tolerance: 4.773e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.540e+06, tolerance: 3.665e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.840e+06, tolerance: 4.051e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.328e+06, tolerance: 4.314e+03\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.197e+06, tolerance: 4.496e+03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned results for ElasticNet: Alpha: 1, L1 Ratio: 0.5, R2: 0.30438575498623055\n",
      "Mean Squared Error (MSE): 103925.2188789196\n",
      "   Predictors  Coefficient\n",
      "3        CRBI    51.418093\n",
      "2       CRuns    51.147212\n",
      "4        Hits    50.438391\n",
      "7       CHits    47.055698\n",
      "6       Walks    46.931845\n",
      "5     PutOuts    45.615099\n",
      "1  Division_W   -32.357492\n",
      "0  Division_E    32.357475\n",
      "8      Errors   -11.047745\n",
      "Tuned results for ElasticNet: Alpha: 1, L1 Ratio: 0.5, R2: 0.30438575498623055\n",
      "Mean Squared Error (MSE): 103925.2188789196\n",
      "   Predictors  Coefficient\n",
      "3        CRBI    51.418093\n",
      "2       CRuns    51.147212\n",
      "4        Hits    50.438391\n",
      "7       CHits    47.055698\n",
      "6       Walks    46.931845\n",
      "5     PutOuts    45.615099\n",
      "1  Division_W   -32.357492\n",
      "0  Division_E    32.357475\n",
      "8      Errors   -11.047745\n"
     ]
    }
   ],
   "source": [
    "# Narrowing X down to True Best Predictors (Combination of Lasso and ElasticNet Coefficients)\n",
    "X = hitters[['CRuns','CRBI', 'Hits', 'PutOuts', 'Walks','Division','CHits','Errors']]\n",
    "y = hitters['Salary'].dropna()\n",
    "X = X.loc[y.index]  # Ensure X matches y's non-NaN rows\n",
    "\n",
    "# Elastic Net Interaction was Best Pipeline\n",
    "best_params = tune_with_interactions(ElasticNet(), feature_data=X, target=y)\n",
    "best_lambda = best_params['alpha']\n",
    "best_l1_ratio = best_params['l1_ratio']\n",
    "\n",
    "# Define and fit the final pipeline\n",
    "elastic_pipeline = Pipeline([\n",
    "    (\"preprocessing\", create_column_transformer()),  # Assuming create_column_transformer() is already defined\n",
    "    (\"elastic_net\", ElasticNet(alpha=best_lambda, l1_ratio=best_l1_ratio))\n",
    "])\n",
    "elastic_pipeline.fit(X, y)\n",
    "\n",
    "# Retrieve feature names and coefficients from the best model\n",
    "cat_features = elastic_pipeline.named_steps[\"preprocessing\"].named_transformers_[\"one_hot\"].get_feature_names_out(\n",
    "    input_features=X.select_dtypes(include=object).columns\n",
    ")\n",
    "num_features = X.select_dtypes(include=np.number).columns\n",
    "variables = list(cat_features) + list(num_features)\n",
    "elastic_net_coef = elastic_pipeline.named_steps[\"elastic_net\"].coef_\n",
    "\n",
    "# Display most significant coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    \"Predictors\": variables,\n",
    "    \"Coefficient\": elastic_net_coef\n",
    "})\n",
    "\n",
    "# Sort coefficients by absolute value for significance\n",
    "coef_df = coef_df.reindex(coef_df['Coefficient'].abs().sort_values(ascending=False).index)\n",
    "\n",
    "# Calculate and display MSE of the final model\n",
    "y_pred = elastic_pipeline.predict(X)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# Display top 10 coefficients\n",
    "print(coef_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(\n",
    "    p9.ggplot(coef_df, p9.aes(x=\"Predictors\", y=\"Coefficient\", fill=\"Coefficient > 0\")) \n",
    "    + p9.geom_bar(stat=\"identity\", show_legend=False) \n",
    "    + p9.labs(\n",
    "        title=\"Final Model for Predicting Baseball Players' Salaries\",\n",
    "        x=\"Predictors\",\n",
    "        y=\"Coefficient\")\n",
    "    + p9.theme_minimal()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows the most significant predictors for predicting baseball player's salaries using a Elastic Net model. Increases in salary is shown in blue, while decreases are shown in red. It has a $\\lambda$ of 1 and a MSE of 103925.22. The largest coefficients are CRBI and CRuns, and the smallest coefficients being Division_E and Division_W, which are the only two negative impact on salary."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "raw"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
